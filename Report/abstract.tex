%!TEX root = report.tex

\begin{abstract}
{With global temperatures on the rise, forest fires are becoming more frequent and forest fires, in turn, contribute to global warming by releasing large amounts of CO$_{2}$ into the atmosphere and eliminating the trees that would be able to process the CO$_{2}$. Finding a way to effectively control and contain these fires is therefore becoming more and more of a priority.
In this paper, we propose a connectionist reinforcement learning system that can learn to contain the spread of a simulated fire. It can do this by cutting fire lines around the fire, removing the fuel needed for it to spread further.
We show the performance of a connectionist $Q$-Learning algorithm with a target network and experience replay, and compare it to three other algorithms. One that uses the on-policy algorithm SARSA, one with the addition of a dueling network architecture and one with both modifications.
To accelerate learning, we use a state representation in which the system receives as input three versions of the full map size each showing only a single feature such as agent location and fire locations. We also provide the algorithm with different amounts of demonstration data.
The results show the ability of each proposed system to successfully contain the fire within a reasonable number of training episodes. Both modifications have their advantages and disadvantages with regard to reliance on demonstration data and learning stability. Dueling SARSA, combining both modifications, shows the best performance.

\vspace{6ex}}
\end{abstract}
