% Original DQN Paper (well, second edition)
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

% The big book
@book{sutton_barto_2018, 
  title={Reinforcement learning: an introduction}, 
  publisher={The MIT Press.}, 
  author={Sutton, Richard S.. and Barto, Andrew G..}, 
  year={2018}
 }

% Double Q-Learning (Target Networks)
@incollection{NIPS2010_3964,
  title = {Double Q-learning},
  author = {Hado V. Hasselt},
  booktitle = {Advances in Neural Information Processing Systems 23},
  editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
  pages = {2613--2621},
  year = {2010},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/3964-double-q-learning.pdf}
}

% Original Experience Replay
@Article{Lin1992,
  author="Lin, Long-Ji",
  title="Self-improving reactive agents based on reinforcement learning, planning and teaching",
  journal="Machine Learning",
  year="1992",
  month="May",
  day="01",
  volume="8",
  number="3",
  pages="293--321",
  abstract="To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.",
  issn="1573-0565",
  doi="10.1007/BF00992699",
  url="https://doi.org/10.1007/BF00992699"
}

% Hindsight actual benefits of experience replay
@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

% Vision grids (Marco)
@inproceedings{knegt2018opponent,
  title={Opponent Modelling in the Game of Tron using Reinforcement Learning.},
  author={Knegt, Stefan JL and Drugan, Madalina M and Wiering, Marco A},
  booktitle={ICAART (2)},
  pages={29--40},
  year={2018}
}