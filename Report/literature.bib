% Climate change
@book{houghton1991climate,
  title={Climate change},
  author={Houghton, J. and Jenkins, T. and Ephraums, G.},
  publisher={Cambridge University Press},
  address={Cambridge (UK)},
  edition={3},
  year={1991}
}

% Basic forest fire/carbon stuff
@article{kasischke1995fire,
  title={Fire, global warming, and the carbon balance of boreal forests},
  author={Kasischke, E. and Christensen Jr, N. and Stocks, B.},
  journal={Ecological applications},
  volume={5},
  pages={437-451},
  year={1995},
}

% Original DQN Paper (well, second edition)
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, V. and Kavukcuoglu, K. and Silver, D. and Rusu, A. and Andrei, A. and Veness, J. and Bellemare, M. and Fidjeland, K. and Ostrovski, G. et al.},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

% Policy correlation feedback loops
@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, J. and Van Roy, B.},
  booktitle={Advances in neural information processing systems},
  pages={1075-1081},
  year={1997}
}

% SARSA
@techreport{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, G. and Niranjan, M.},
  year={1994},
  institution={University of Cambridge, Department of Engineering Cambridge, England}
}

% Q-Learning
@phdthesis{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, C.},
  year={1989},
  school={University of Cambridge}
}

% The big book
@book{sutton_barto_2018, 
  title={Reinforcement Learning: an Introduction}, 
  publisher={The MIT Press}, 
  edition={2},
  author={Sutton, R. and Barto, A.}, 
  year={2018}
}

% Double Q-Learning
% !NEVER MENTIONED!
@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, H.V.},
  editor={Lafferty, J. and Williams, C. and Shawe-Taylor, J. and Zemel, R. and Culotta, A.},
  booktitle={Advances in Neural Information Processing Systems},
  volume={23},
  pages={2613-2621},
  publisher={Curran Associates, Inc.},
  year={2010}
}

% Original Experience Replay
@Article{Lin1992,
  author="Lin, Long-Ji",
  title="Self-improving reactive agents based on reinforcement learning, planning and teaching",
  journal="Machine Learning",
  year="1992",
  month="May",
  day="01",
  volume="8",
  number="3",
  pages="293--321",
  abstract="To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.",
  issn="1573-0565",
  doi="10.1007/BF00992699",
  url="https://doi.org/10.1007/BF00992699"
}

% Self-improving reactive..
% !NEVER MENTIONED!
@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  journal={Machine Learning},
  volume={8},
  number={3},
  pages={293-321},
  year={1992}
}

% Hindsight actual benefits of experience replay
@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, T. and Quan, J. and Antonoglou, I. and Silver, D.},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

% Vision grids (Marco)
@inproceedings{knegt2018opponent,
  title={Opponent Modelling in the Game of Tron using Reinforcement Learning},
  author={Knegt, S.J.L. and Drugan, M.M. and Wiering, M.A.},
  booktitle={International Conference on Agents and Artificial Intelligence},
  year={2018}
}

% Dueling Q-Networks
@article{wang2015dueling,
  title={Dueling Network Architectures for Deep Reinforcement Learning},
  author={Wang, Z. and De Freitas, N. and Lanctot, M.},
  journal={arXiv e-prints},
  year={2015}
}

% Wiering 1
@inproceedings{wiering1998learning,
  title={Learning to control forest fires},
  author={Wiering, M.A. and Doringo, M.},
  editor={Haasis, H. and Ranze, K.},
  year={1998},
  booktitle={Proceedings of the 12th international Symposium on 'Computer Science for Environmental Protection'},
  pages={378-388}
}

% Wiering 2
@inproceedings{wiering2005evolving,
  title={Evolving neural networks for forest fire control},
  author={Wiering, M.A. and Midgogna, F. and Maassen, B.},
  editor={van Otterlo, M. and Poel, M. and Nijholt, A.},
  booktitle={Benelearn '05: Proceedings of the 14th Belgian-Dutch Conference on Machine Learning},
  pages={113-120},
  year={2005}
}
